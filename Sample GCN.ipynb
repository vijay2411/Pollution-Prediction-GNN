{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('D:\\STUDIES\\BTP\\Data From Param\\submit\\graphsage\\data.csv')\n",
    "Data1Hr = dataset[dataset['GENERATION_TIME']<'2012.02.01 01:00']\n",
    "data = Data1Hr[['LATITUDE','LONGITUDE', 'OZONE_PPB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     LATITUDE  LONGITUDE  OZONE_PPB\n",
      "0    1.159329   0.217775  -2.267350\n",
      "1    0.277968  -0.173864  -1.640807\n",
      "2   -0.874582  -0.102657  -1.780039\n",
      "3   -1.654248  -2.523696  -2.093310\n",
      "4   -1.281364  -1.241969  -2.511005\n",
      "..        ...        ...        ...\n",
      "175  0.142374  -0.245071   1.317867\n",
      "176  0.549156  -1.063952   0.830556\n",
      "177  1.667807  -0.067053   1.178635\n",
      "178  1.837300   0.680621   1.317867\n",
      "179  1.261025  -0.316278   1.317867\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "normalizeData = (data - data.mean(axis = 0)) / data.std(axis = 0)\n",
    "npData = normalizeData.to_numpy(dtype = float)\n",
    "print(normalizeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "trainRatio = 0.95\n",
    "trainMask = random.sample(list(range(npData.shape[0])),int(npData.shape[0]*trainRatio))\n",
    "trainMask.sort()\n",
    "len(trainMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   1,   2,   3,   4,   4,   5,   6,   6,   7,   7,   8,\n",
       "          8,   9,   9,  10,  11,  11,  11,  11,  12,  12,  12,  13,  14,\n",
       "         15,  16,  17,  17,  17,  17,  17,  18,  18,  19,  19,  20,  20,\n",
       "         21,  21,  21,  21,  22,  23,  24,  24,  25,  25,  26,  26,  27,\n",
       "         27,  27,  28,  28,  28,  28,  29,  30,  30,  31,  32,  33,  34,\n",
       "         35,  36,  36,  36,  36,  37,  37,  37,  37,  37,  38,  39,  39,\n",
       "         40,  40,  41,  41,  42,  42,  43,  43,  44,  44,  45,  45,  46,\n",
       "         46,  47,  47,  48,  49,  50,  51,  52,  52,  53,  53,  54,  55,\n",
       "         55,  56,  56,  57,  57,  57,  58,  59,  59,  60,  60,  61,  62,\n",
       "         62,  63,  64,  64,  64,  65,  65,  66,  66,  67,  68,  69,  70,\n",
       "         70,  70,  71,  71,  72,  72,  73,  73,  74,  74,  74,  74,  74,\n",
       "         75,  75,  75,  75,  76,  76,  77,  77,  78,  78,  79,  80,  80,\n",
       "         81,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  91,\n",
       "         92,  92,  93,  94,  94,  95,  95,  96,  96,  97,  97,  98,  99,\n",
       "         99, 100, 101, 101, 102, 102, 103, 104, 104, 105, 106, 106, 106,\n",
       "        106, 106, 107, 108, 109, 110, 110, 110, 111, 112, 113, 114, 114,\n",
       "        115, 115, 115, 115, 115, 116, 116, 117, 118, 118, 119, 119, 120,\n",
       "        120, 120, 121, 121, 122, 122, 122, 123, 124, 125, 126, 126, 127,\n",
       "        128, 129, 129, 129, 130, 130, 131, 132, 133, 133, 134, 134, 135,\n",
       "        135, 136, 136, 137, 138, 139, 139, 140, 141, 141, 142, 142, 143,\n",
       "        144, 145, 146, 147, 148, 149, 149, 150, 150, 151, 151, 152, 153,\n",
       "        154, 155, 155, 156, 156, 157, 157, 158, 158, 159, 159, 160, 161,\n",
       "        162, 162, 163, 164, 164, 165, 165, 166, 166, 167, 167, 168, 168,\n",
       "        169, 169, 170, 171, 171, 172, 172, 172, 172, 173, 173, 173, 174,\n",
       "        175, 175, 176, 176, 177, 177, 178, 179],\n",
       "       [  0, 134,   1,   2,   3,  11,   4,   5,  57,   6,   8,   7,   7,\n",
       "          8,  42,   9,  10,   4,  26, 114,  11,  64, 135,  12,  13,  14,\n",
       "         15,  16,  37,  74, 115, 172,  17, 151,  18, 101,  19, 120,  20,\n",
       "         28,  36, 106,  21,  22,  23,  77,  24, 110,  25,  11,  26,  70,\n",
       "        122,  27,  21,  36, 106,  28,  29,  52,  30,  31,  32,  33,  34,\n",
       "         35,  21,  28, 106,  36,  17,  74, 115, 172,  37,  38,  96,  39,\n",
       "        162,  40,  91,  41,   9,  42, 155,  43,  76,  44, 102,  45, 116,\n",
       "         46,  53,  47,  48,  49,  50,  51,  30,  52,  47,  53,  54,  56,\n",
       "         55,  55,  56,   6, 173,  57,  58,  60,  59,  59,  60,  61, 121,\n",
       "         62,  63,  12,  65,  64,  64,  65, 129,  66,  67,  68,  69,  27,\n",
       "        122,  70, 169,  71,  75,  72, 106,  73,  17,  37, 115, 172,  74,\n",
       "         72, 133, 175,  75,  44,  76,  24,  77, 136,  78,  79,  81,  80,\n",
       "         80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  41,  91,\n",
       "        104,  92,  93, 167,  94, 168,  95,  39,  96, 120,  97,  98, 149,\n",
       "         99, 100,  19, 101,  45, 102, 103,  92, 104, 105,  21,  28,  36,\n",
       "         73, 106, 107, 108, 109,  25, 130, 110, 111, 112, 113,  11, 114,\n",
       "         17,  37,  74, 159, 115,  46, 116, 117, 157, 118, 158, 119,  20,\n",
       "         97, 120,  62, 121,  27,  70, 122, 123, 124, 125, 173, 126, 127,\n",
       "        128,  66, 164, 129, 110, 130, 131, 132,  75, 133,   1, 134,  12,\n",
       "        135,  78, 136, 137, 138, 176, 139, 140, 142, 141, 141, 142, 143,\n",
       "        144, 145, 146, 147, 148,  99, 149, 171, 150,  18, 151, 152, 153,\n",
       "        154,  43, 155, 177, 156, 118, 157, 119, 158, 115, 159, 160, 161,\n",
       "         40, 162, 163, 129, 164, 166, 165, 165, 166,  94, 167,  95, 168,\n",
       "         71, 169, 170, 150, 171,  17,  37,  74, 172,  57, 126, 173, 174,\n",
       "         75, 175, 139, 176, 156, 177, 178, 179]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = npData[:,:2]\n",
    "Y = torch.tensor(npData[:,2], dtype = torch.float)\n",
    "edgeList = []\n",
    "Adj = np.zeros((X.shape[0],X.shape[0]))\n",
    "dist = 0.015\n",
    "size = X.shape[0]\n",
    "for i in range(size):\n",
    "    for j in range(size):\n",
    "        if i!=j:\n",
    "            d = (X[i][0]-X[j][0])**2 + (X[i][1] - X[j][1])**2\n",
    "            if(d<dist):\n",
    "                edgeList.append([i,j])\n",
    "                Adj[i][j] = 1\n",
    "    edgeList.append([i,i])\n",
    "                \n",
    "edges = np.array(edgeList)\n",
    "edges = edges.T\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "x,y,e,trainMask = torch.tensor(X), torch.tensor(Y, dtype = torch.float), torch.tensor(edges, dtype = torch.long), torch.tensor(trainMask, dtype = torch.long)\n",
    "graph = Data(x = x, edge_index = e, y = y, train_mask = trainMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(edge_index=[2, 320], train_mask=[171], x=[180, 2], y=[180]), True, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph, graph.contains_self_loops(), graph.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): GCNConv(2, 4)\n",
       "  (batch1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): GCNConv(4, 3)\n",
       "  (batch2): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (batch3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (conv5): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(2, 4)\n",
    "        self.batch1 = nn.BatchNorm1d(4)        \n",
    "        self.conv2 = GCNConv(4, 3)\n",
    "        self.batch2 = nn.BatchNorm1d(3)\n",
    "        self.conv3 = nn.Linear(3, 4)\n",
    "        self.batch3 = nn.BatchNorm1d(4)\n",
    "        self.conv4 = nn.Linear(4, 3)\n",
    "        self.conv5 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        x, edge_index = data.x.float(), data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.sigmoid(self.conv2(x, edge_index))\n",
    "        self.saveLaplacianError(x,data)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.conv5(x)\n",
    "        return torch.squeeze(x)\n",
    "    \n",
    "    def saveLaplacianError(self, x, data):\n",
    "        A = torch_geometric.utils.get_laplacian(data.edge_index)\n",
    "        Amat = torch.zeros(data.x.shape[0], data.x.shape[0])\n",
    "        for i in range(len(A[1])):\n",
    "            Amat[A[0][0][i].item(),A[0][1][i].item()] = A[1][i].item()\n",
    "        Amat = Amat.float()\n",
    "        P = torch.mm(torch.mm(torch.transpose(x.float(),0,1),Amat.float()),x.float())\n",
    "        self.llLoss = torch.sum(torch.diag(P))\n",
    "\n",
    "net = Net()\n",
    "net = net.float()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = net(graph)\n",
    "    print(output.shape)\n",
    "    loss = F.mse_loss(output[graph.train_mask],Y[graph.train_mask])\n",
    "    print(type(loss))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([180])\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.8354, grad_fn=<MseLossBackward>) 755\n"
     ]
    }
   ],
   "source": [
    "out = torch.randn(5)\n",
    "for epoch in range(1):\n",
    "    loss, out = train()\n",
    "    print(loss,i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.1309e-01, -2.1309e-01, -5.5806e-02, -5.2054e-01, -2.1309e-01,\n",
       "         -2.1309e-01, -6.2509e-01, -6.2509e-01, -6.2509e-01, -2.1309e-01,\n",
       "          2.8082e-02, -2.1309e-01, -2.1309e-01, -2.1309e-01, -4.1778e-01,\n",
       "         -6.2509e-01, -6.2509e-01, -2.1309e-01, -3.0953e-01, -2.4578e-01,\n",
       "         -3.9029e-01, -5.6000e-01, -6.2509e-01, -6.2509e-01, -4.7669e-01,\n",
       "          1.0085e-01, -2.1309e-01, -1.2410e-01, -5.6000e-01, -2.1309e-01,\n",
       "         -5.5110e-01,  2.2002e-01, -2.1309e-01, -4.2201e-01, -5.2792e-01,\n",
       "         -2.1309e-01, -5.6000e-01, -2.1309e-01, -5.8211e-01, -7.9064e-02,\n",
       "          3.9919e-01, -2.6378e-03, -2.1309e-01, -2.6720e-01, -6.2509e-01,\n",
       "         -2.1309e-01, -2.1309e-01, -5.7676e-01, -4.9495e-01, -6.2509e-01,\n",
       "         -6.2509e-01, -2.1309e-01, -5.5110e-01, -5.7676e-01, -6.2509e-01,\n",
       "         -6.2509e-01, -6.2509e-01, -6.2509e-01, -4.2092e-01, -3.2420e-01,\n",
       "         -3.2420e-01,  2.9301e-01, -1.4416e-01, -2.1309e-01, -2.1309e-01,\n",
       "         -2.1309e-01, -2.1309e-01,  1.3944e-01,  7.6825e-01, -1.3595e-01,\n",
       "         -1.2410e-01, -1.9931e-01, -2.1309e-01, -1.7891e-01, -2.1309e-01,\n",
       "         -2.1309e-01, -6.2509e-01, -4.7669e-01, -1.5491e-04,  1.1040e-01,\n",
       "          6.5047e-01,  6.5047e-01,  2.5691e-01,  3.2027e-01,  4.7102e-02,\n",
       "          1.5783e-01,  8.3834e-01,  3.8325e-01,  6.4446e-01,  4.6663e-01,\n",
       "          2.0970e-01, -2.6378e-03, -2.1309e-01, -4.6169e-01,  5.2451e-01,\n",
       "          8.3709e-01, -7.9064e-02, -3.3159e-01, -4.1257e-01, -2.1309e-01,\n",
       "         -2.1309e-01, -2.4578e-01, -2.1309e-01, -3.6421e-01, -2.1309e-01,\n",
       "         -2.1309e-01, -1.8448e-01, -2.1309e-01,  4.3621e-01,  7.8980e-01,\n",
       "          2.0494e-01,  4.9420e-01,  3.6386e-01,  2.7684e-01, -2.1309e-01,\n",
       "         -2.1309e-01, -2.1309e-01, -2.1309e-01,  6.0293e-01,  8.8943e-01,\n",
       "         -5.3186e-01, -1.4416e-01, -1.2410e-01,  3.0992e-01,  2.0712e-01,\n",
       "          9.1424e-02, -6.2509e-01, -6.2509e-01, -2.1309e-01, -2.1309e-01,\n",
       "          1.1864e-01,  2.8127e-02, -2.1309e-01, -2.1309e-01, -2.1309e-01,\n",
       "         -2.1309e-01, -1.5491e-04,  8.2574e-02,  2.0287e-01,  1.2261e-01,\n",
       "          7.4285e-01,  6.9638e-01,  6.9638e-01,  8.2970e-01,  1.1900e+00,\n",
       "          1.3410e+00,  6.6372e-01,  6.4472e-01, -1.4570e-01, -2.1309e-01,\n",
       "         -2.1309e-01, -3.0953e-01, -3.7739e-01, -2.1309e-01, -2.1309e-01,\n",
       "         -2.6720e-01, -2.1309e-01,  6.0293e-01,  8.8943e-01, -2.1309e-01,\n",
       "          1.0046e+00,  7.1778e-01,  3.9919e-01, -1.0310e-01, -2.1575e-01,\n",
       "         -2.1309e-01, -2.1309e-01,  5.2451e-01,  8.3709e-01, -1.9931e-01,\n",
       "         -2.1309e-01, -2.1309e-01, -2.1309e-01, -6.2509e-01, -5.7663e-03,\n",
       "         -2.1309e-01,  1.2261e-01, -2.1309e-01, -2.1309e-01, -2.1309e-01],\n",
       "        grad_fn=<SqueezeBackward0>),\n",
       " tensor([-2.2673, -1.6408, -1.7800, -2.0933, -2.5110, -1.5016, -1.3275, -1.3275,\n",
       "         -1.1883, -1.3275, -1.3275, -1.1883, -1.5016, -1.0491, -0.9098, -1.0491,\n",
       "         -1.0491, -0.5966, -0.9098, -1.0491, -0.9098, -1.1883, -0.7358, -1.1883,\n",
       "         -1.1883, -1.3275, -0.9098, -1.0491, -1.0491, -1.7800, -1.6408, -1.1883,\n",
       "         -1.1883, -1.1883, -1.6408, -2.5110, -1.9541, -1.9541, -1.7800, -2.0933,\n",
       "         -1.7800, -1.9541, -1.6408, -1.3275, -1.7800, -1.5016, -0.9098, -0.9098,\n",
       "         -0.7358, -1.1883, -0.9098, -0.9098, -1.3275, -0.9098, -0.4225, -0.4225,\n",
       "          0.0648, -0.0745,  0.2040,  0.0648, -0.0745, -0.2833,  0.2040, -0.0745,\n",
       "         -0.0745,  0.3781,  0.6565,  0.0648,  0.2040,  0.3781,  0.5173, -0.0745,\n",
       "          0.3781,  0.0648,  0.3781,  0.3781,  0.3781, -0.0745,  0.3781,  0.0648,\n",
       "          0.6565,  0.5173, -0.0745,  0.5173,  0.3781,  0.5173,  0.5173,  0.6565,\n",
       "          1.0046,  0.2040,  0.5173,  0.8306,  1.0046,  0.0648,  0.6565,  0.5173,\n",
       "          0.5173,  0.6565,  1.0046,  0.6565,  0.8306,  0.8306,  0.6565,  0.3781,\n",
       "          0.6565,  1.0046,  0.2040,  0.6565,  1.3179,  1.1786,  1.1786,  0.6565,\n",
       "          0.8306,  0.8306,  0.8306,  1.3179,  1.0046,  0.8306,  0.6565,  0.6565,\n",
       "          0.3781,  0.8306,  0.3781,  0.5173,  0.2040,  0.0648,  0.0648,  0.3781,\n",
       "          0.3781,  0.0648, -0.0745,  0.0648,  0.0648,  0.2040, -0.0745,  0.2040,\n",
       "          0.3781,  0.6565,  0.8306,  0.0648,  0.3781,  0.6565,  0.3781, -0.0745,\n",
       "          0.5173,  0.6565,  1.0046,  0.8306,  0.6565,  1.0046,  0.8306,  1.0046,\n",
       "          1.1786,  1.0046,  1.3179,  1.0046,  1.0046,  1.0046,  1.1786,  0.8306,\n",
       "          0.6565,  1.4571,  0.8306,  1.0046,  1.1786,  1.0046,  0.8306,  1.1786,\n",
       "          1.0046,  1.3179,  0.5173,  1.4571,  0.8306,  0.8306,  0.8306,  1.3179,\n",
       "          0.8306,  1.1786,  1.3179,  1.3179]))"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "net(graph),Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(78)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(out-Y)>0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
